{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06ca2c74",
   "metadata": {},
   "source": [
    "Install and import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lxml\n",
    "!pip install serpapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9d2c0a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from urllib.parse import urlencode, urlunparse\n",
    "from urllib.request import urlopen, Request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8dce40",
   "metadata": {},
   "source": [
    "Load stratups JSON data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b1c2c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('') as f: #startups_json.txt\n",
    "    json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "22993fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json_data['data']\n",
    "startups_list = data['startups']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ae36dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in startups_list:\n",
    "    for val in obj:\n",
    "        #print(obj[val])\n",
    "        if(str(val)!='website'):\n",
    "            #print(str(val))\n",
    "            obj[val] = re.sub('<[^<]+?>', '', str(obj[val]))\n",
    "        elif(str(val)=='website'):\n",
    "            #obj[val] = re.sub('\\\\\\\\', '', str(obj[val]))\n",
    "            #print(obj[val])\n",
    "            soup = BeautifulSoup(str(obj[val]),\"html.parser\")\n",
    "            tag = soup.find('a', href=True)\n",
    "            obj[val] = str(tag['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c96cff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(startups_list, orient='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b91a0d",
   "metadata": {},
   "source": [
    "Functions to search and extract urls based on company name and website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5911a69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                  \"(KHTML, like Gecko) Chrome/111.0.5563.65 Safari/537.36\"}\n",
    "\n",
    "def extract_elements(html_text, elm='p'):\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    paragraphs = []\n",
    "    for p in soup.find_all(elm):\n",
    "        paragraphs.append(p.text.strip())\n",
    "    return paragraphs\n",
    "\n",
    "def google_search_alt(q: str):\n",
    "    time.sleep(3)\n",
    "    params = {'q': q}\n",
    "    #html = requests.get('https://www.google.com/search', headers=headers, params=params).text\n",
    "    html = requests.get('https://www.bing.com/search', headers=headers, params=params).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    elms = extract_elements(str(soup), elm='cite')\n",
    "    #print(elms)\n",
    "    return elms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f56782",
   "metadata": {},
   "source": [
    "Form search query term and add to a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "550216ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_website_list = []\n",
    "for index in range(len(df)):\n",
    "    name_website_list.append(df['startup'].iloc[index] +' '+ df['website'].iloc[index]+' linkedin about')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0edc032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name_website_list'] = name_website_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c1b4084f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      FlexFin Μονοπρόσωπη Ανώνυμη Εταιρεία Πρακτορεί...\n",
       "1      Infiniti Platforms Greece Ltd. https://infinit...\n",
       "2           Optechain PC https://optechain.com/ linkedin\n",
       "3      MENTIONLYTICS IKE https://www.mentionlytics.co...\n",
       "4      Biomimetic Private Company https://www.biomime...\n",
       "                             ...                        \n",
       "706    [i2.d] technologies https://www.i2-d.com linkedin\n",
       "707           MEDINEVO https://www.medinevo.com linkedin\n",
       "708       PRAGMA-IOT SA https://pragma-iot.com/ linkedin\n",
       "709      UME MONOΠΡΟΣΩΠΗ ΙΚΕ https://www.ume.ai linkedin\n",
       "710    Dataphoria P.C. https://www.dataphoria.gr/ lin...\n",
       "Name: name_website_list, Length: 711, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name_website_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5bbe8bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    FlexFin Μονοπρόσωπη Ανώνυμη Εταιρεία Πρακτορεί...\n",
      "Name: name_website_list, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[:1]['name_website_list'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e80ed2",
   "metadata": {},
   "source": [
    "Loop through dataframe and extract url list from the search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb916e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_list = []\n",
    "i = 0\n",
    "for index in range(len(df)):\n",
    "    i = i +1\n",
    "    website = df['name_website_list'].iloc[index]\n",
    "    url = google_search_alt(q=website)\n",
    "    if(len(url)>0):\n",
    "        linkedin_list.append(url)\n",
    "    else:\n",
    "        linkedin_list.append([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d87776",
   "metadata": {},
   "source": [
    "Create a new column with the extracted data and save file as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "51f76188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['linkedin_list'] = linkedin_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "4efcffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('linked_in_scrape_v2', sep='\\t', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
